{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590541f1",
   "metadata": {},
   "source": [
    "# <center> pyspark presentation \n",
    "    <center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3234a96",
   "metadata": {},
   "source": [
    "# $\\color{red}{\\text{Tasks for first week:}}$\n",
    "\n",
    " ## 1-calculate distance of each trip using haversine library and add the result to the dataset\n",
    " ## 2-calculate the duration in seconds of each trip\n",
    " ## 3-by assuming each minute cost 0.35 cent calculate the fee for each trip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cfdce1",
   "metadata": {},
   "source": [
    "# $\\color{red}{\\text{Tasks for second week :}}$\n",
    " ## 1-calculate the total distance for each bike and list the top 10\n",
    " ## 2-calculate the number of trips for each start station list top 10 and find the ratio of using as male or female\n",
    " ## 3-make a comparison to find the percentage of usage for customer and subscriber\n",
    " ## 4-calculate the age of all users and show the relation between the distance and the age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabaf8e1",
   "metadata": {},
   "source": [
    "# $\\color{red}{\\text{Tasks for third week :}}$ \n",
    " ## 1-calculate the total cost for all customers and all subscribers\n",
    " ## 2- what is the ratio of payment using cc or app wallet\n",
    " ## 3-what is the preferred way to pay for customers and subscriber"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d9a20",
   "metadata": {},
   "source": [
    "Ideas for presentaion :\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a0fff2",
   "metadata": {},
   "source": [
    " ## 1-calculate distance of each trip using haversine library and add the result to the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f52f72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import sqrt\n",
    "spark = SparkSession.builder.appName(\"MyApp\").getOrCreate()\n",
    "df = spark.read.csv('Downloads/2017-fordgobike-tripdata.csv', header=True, inferSchema=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3af5bf5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "|start_time|end_time|start_station_id|  start_station_name|start_station_latitude|start_station_longitude|end_station_id|    end_station_name|end_station_latitude|end_station_longitude|bike_id| user_type|member_birth_year|member_gender|     pyment|        distance_m|\n",
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "|   57:39.7| 12:50.2|              74|Laguna St at Haye...|           37.77643482|            -122.426244|            43|San Francisco Pub...|          37.7787677|         -122.4159292|     96|  Customer|             1987|         Male|credit card| 942.3373818591812|\n",
      "|   56:34.8| 49:55.6|             284|Yerba Buena Cente...|           37.78487208|           -122.4008757|            96|Dolores St at 15t...|          37.7662102|         -122.4266136|     88|  Customer|             1965|       Female|credit card|3067.7986569373347|\n",
      "|   45:48.4| 28:36.9|             245|Downtown Berkeley...|            37.8703477|           -122.2677637|           245|Downtown Berkeley...|          37.8703477|         -122.2677637|   1094|  Customer|             null|         null|credit card|               0.0|\n",
      "|   31:10.6| 47:23.5|              60|8th St at Ringold St|            37.7745204|           -122.4094494|             5|Powell St BART St...|         37.78389936|         -122.4084449|   2831|  Customer|             null|         null|credit card|1045.9655184811572|\n",
      "|   23:14.0| 29:57.6|             239|Bancroft Way at T...|            37.8688126|            -122.258764|           247|Fulton St at Banc...|          37.8677892|         -122.2658964|   3167|Subscriber|             1997|       Female| app wallet| 635.9398610767416|\n",
      "|   51:00.9| 24:47.2|              30|San Francisco Cal...|             37.776598|            -122.395282|            30|San Francisco Cal...|           37.776598|          -122.395282|   1487|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   49:28.4| 04:35.6|             259|Addison St at Fou...|             37.866249|           -122.2993708|           259|Addison St at Fou...|           37.866249|         -122.2993708|   3539|  Customer|             1991|       Female| app wallet|               0.0|\n",
      "|   46:37.2| 58:51.2|             284|Yerba Buena Cente...|           37.78487208|           -122.4008757|           284|Yerba Buena Cente...|         37.78487208|         -122.4008757|   1503|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   37:07.5| 46:18.3|              20|Mechanics Monumen...|               37.7913|            -122.399051|            20|Mechanics Monumen...|             37.7913|          -122.399051|   3125|  Customer|             null|         null| app wallet|               0.0|\n",
      "|   35:38.1| 46:17.1|              20|Mechanics Monumen...|               37.7913|            -122.399051|            20|Mechanics Monumen...|             37.7913|          -122.399051|   2543|  Customer|             null|         null| app wallet|               0.0|\n",
      "+----------+--------+----------------+--------------------+----------------------+-----------------------+--------------+--------------------+--------------------+---------------------+-------+----------+-----------------+-------------+-----------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#from pyspark.sql.functions import acos, cos, sin, radians, least\n",
    "#from pyspark.sql.functions import acos, cos, sin, sqrt, lit\n",
    "from pyspark.sql.functions import sin, cos, sqrt, asin, radians, least, acos, col, lit\n",
    "\n",
    "\n",
    "def haversine(lat1, long1, lat2, long2):\n",
    "    lat1, long1, lat2, long2 = radians(lat1), radians(long1), radians(lat2), radians(long2)\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = long2 - long1\n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a))\n",
    "    m = 6367 * c * 1000\n",
    "    return m\n",
    "\n",
    "\n",
    "# Read the dataset into a Spark DataFrame\n",
    "df = spark.read.csv('Downloads/2017-fordgobike-tripdata.csv', header=True, inferSchema=True)\n",
    "\n",
    "# Calculate the distance for each trip using the Haversine function\n",
    "df = df.withColumn('distance_m', haversine('start_station_latitude', 'start_station_longitude', 'end_station_latitude', 'end_station_longitude'))\n",
    "\n",
    "# Show the first 10 rows of the updated DataFrame\n",
    "df.show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67ee5bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|        distance_m|\n",
      "+------------------+\n",
      "| 942.3373818591812|\n",
      "|3067.7986569373347|\n",
      "|               0.0|\n",
      "|1045.9655184811572|\n",
      "| 635.9398610767416|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "|               0.0|\n",
      "+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('distance_m').show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff9a67f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median distance: 1399.36 meters\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import percentile_approx\n",
    "\n",
    "# Get the median trip distance\n",
    "median_distance = df.selectExpr(\"percentile_approx(distance_m, 0.5)\").collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"Median distance: {:.2f} meters\".format(median_distance))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad8577c",
   "metadata": {},
   "source": [
    " ## 2-calculate the duration in seconds of each trip\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d9b3c04",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import expr\n",
    "from pyspark.sql.functions import abs\n",
    "\n",
    "df = df.withColumn('start_time', expr(\"to_timestamp(start_time, 'mm:ss.S')\"))\n",
    "df = df.withColumn('end_time', expr(\"to_timestamp(end_time, 'mm:ss.S')\"))\n",
    "\n",
    "df = df.withColumn('duration_sec', abs(df.end_time.cast('long') - df.start_time.cast('long')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b73284",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr, when, col\n",
    "\n",
    "df = df.withColumn('start_time', expr(\"to_timestamp(start_time, 'mm:ss.S')\"))\n",
    "df = df.withColumn('end_time', expr(\"to_timestamp(end_time, 'mm:ss.S')\"))\n",
    "\n",
    "df = df.withColumn('duration_sec',\n",
    "                   when(col('end_time') < col('start_time'),\n",
    "                        (col('end_time').cast('long') + 3600 - col('start_time').cast('long')))\n",
    "                   .otherwise(col('end_time').cast('long') - col('start_time').cast('long')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ad3f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: integer (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      " |-- distance_m: double (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema() # _c0 is unneccery column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b97d6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------+\n",
      "|bike_id|duration_sec|\n",
      "+-------+------------+\n",
      "|     96|         911|\n",
      "|     88|        3201|\n",
      "|   1094|        2568|\n",
      "|   2831|         973|\n",
      "|   3167|         403|\n",
      "|   1487|        2027|\n",
      "|   3539|         907|\n",
      "|   1503|         734|\n",
      "|   3125|         551|\n",
      "|   2543|         639|\n",
      "+-------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(col('bike_id'),('duration_sec')).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03dd9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average trip duration is 738.29 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import avg\n",
    "\n",
    "# Calculate the average trip duration in seconds\n",
    "avg_duration = df.agg(avg(\"duration_sec\")).collect()[0][0]\n",
    "\n",
    "# Print the result\n",
    "print(\"The average trip duration is {:.2f} seconds\".format(avg_duration))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b473150",
   "metadata": {},
   "source": [
    "## 3-by assuming each minute cost 0.35 cent calculate the fee for each trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a8d8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import round\n",
    "\n",
    "df = df.withColumn('fee', round(df.duration_sec/60 * 0.35, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8e3a9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|bike_id|  fee|\n",
      "+-------+-----+\n",
      "|     96| 5.31|\n",
      "|     88|18.67|\n",
      "|   1094|14.98|\n",
      "|   2831| 5.68|\n",
      "|   3167| 2.35|\n",
      "|   1487|11.82|\n",
      "|   3539| 5.29|\n",
      "|   1503| 4.28|\n",
      "|   3125| 3.21|\n",
      "|   2543| 3.73|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_fee = df.select(col('bike_id'),('fee')).show(10)\n",
    "df_fee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a0b363",
   "metadata": {},
   "source": [
    "## 4-calculate the total distance for each bike and list the top 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d50cc568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+\n",
      "|bike_id|total_distance|\n",
      "+-------+--------------+\n",
      "|     68|     742901.74|\n",
      "|   2178|     720728.46|\n",
      "|    256|     671493.31|\n",
      "|    235|     669740.32|\n",
      "|   2049|     656414.81|\n",
      "|    441|      656229.1|\n",
      "|   2226|      647415.6|\n",
      "|    796|      646460.7|\n",
      "|    190|     639891.29|\n",
      "|   2365|     639010.34|\n",
      "+-------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Group the data by bike_id and calculate the total distance for each bike\n",
    "grouped_data = df.groupBy(\"bike_id\").agg({\"distance_m\": \"sum\"})\n",
    "\n",
    "# Rename the column from sum(Distance_in_meter) to total_distance\n",
    "grouped_data = grouped_data.withColumnRenamed(\"sum(distance_m)\", \"total_distance\")\n",
    "\n",
    "# Round the total_distance column to 2 decimal places\n",
    "grouped_data = grouped_data.withColumn(\"total_distance\", round(\"total_distance\", 2))\n",
    "\n",
    "# Sort the data by total_distance in descending order and select the top 10\n",
    "top_10 = grouped_data.sort(grouped_data.total_distance.desc()).limit(10)\n",
    "\n",
    "# Show the results\n",
    "top_10.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d31ea9f7",
   "metadata": {},
   "source": [
    "## 5-calculate the number of trips for each start station list top 10 and find the ratio of using as male or female"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b265788f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------------+\n",
      "|  start_station_name|number_of_trips|\n",
      "+--------------------+---------------+\n",
      "|San Francisco Fer...|          15187|\n",
      "|The Embarcadero a...|          13664|\n",
      "|San Francisco Cal...|          12546|\n",
      "|San Francisco Cal...|          12055|\n",
      "|Market St at 10th St|          11960|\n",
      "|Montgomery St BAR...|          11334|\n",
      "|  Berry St at 4th St|          10956|\n",
      "|Powell St BART St...|          10142|\n",
      "|Howard St at Beal...|           9926|\n",
      "|Steuart St at Mar...|           9347|\n",
      "+--------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Group the data by start station and count the number of trips\n",
    "grouped_data = df.groupBy(\"start_station_name\").agg(count(\"start_station_name\").alias(\"number_of_trips\"))\n",
    "\n",
    "# Sort the data by number_of_trips in descending order and select the top 10\n",
    "top_10 = grouped_data.sort(grouped_data.number_of_trips.desc()).limit(10)\n",
    "\n",
    "# Show the results\n",
    "top_10.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd28189e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------+-----+\n",
      "|member_gender|gender_count|ratio|\n",
      "+-------------+------------+-----+\n",
      "|         null|           0|  0.0|\n",
      "|       Female|       98621| 0.22|\n",
      "|        Other|        6299| 0.01|\n",
      "|         Male|      348318| 0.77|\n",
      "+-------------+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import count, sum, col, round\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Group the data by member_gender and calculate the count for each gender\n",
    "gender_count = df.groupBy(\"member_gender\").agg(count(\"member_gender\").alias(\"gender_count\"))\n",
    "\n",
    "# Calculate the total count of all genders\n",
    "total_count = gender_count.agg(sum(\"gender_count\")).collect()[0][0]\n",
    "\n",
    "# Calculate the ratio of each gender and round to 2 decimal places\n",
    "gender_ratio = gender_count.withColumn(\"ratio\", round(col(\"gender_count\") / total_count, 2))\n",
    "\n",
    "# Show the results\n",
    "gender_ratio.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10b9d688",
   "metadata": {},
   "source": [
    " ## 6-make a comparison to find the percentage of usage for customer and subscriber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4cd93f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+----------+\n",
      "| user_type| total|percantage|\n",
      "+----------+------+----------+\n",
      "|Subscriber|409230|      79.0|\n",
      "|  Customer|110470|      21.0|\n",
      "+----------+------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "percent_user = df.groupBy('user_type').agg(count('*').alias('total'))\n",
    "\n",
    "percent_user.withColumn('percantage',round(col('total')/ df.count()*100)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75418f7e",
   "metadata": {},
   "source": [
    " ## 7-calculate the age of all users and show the relation between the distance and the age"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cc16a059",
   "metadata": {},
   "source": [
    "from pyspark.sql.functions import datediff, year, round, dayofyear, date_sub, to_date\n",
    "\n",
    "# Convert the member_birth_year column to a date data type\n",
    "df = df.withColumn(\"member_birth_year\", to_date(df[\"member_birth_year\"].cast(\"string\"), \"yyyy\"))\n",
    "\n",
    "# Calculate the age of each user based on their birth year\n",
    "df = df.withColumn(\"age\", round(datediff(df[\"start_time\"], date_sub(df[\"member_birth_year\"], 365*dayofyear(df[\"member_birth_year\"]))) / 365))\n",
    "\n",
    "# Show the relation between the distance and the age\n",
    "df.groupBy(\"age\").agg({\"distance_m\": \"mean\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fad4972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the age of each user\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "df1 = df.withColumn(\"age\", 2022 - F.col(\"member_birth_year\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c80af5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- start_time: timestamp (nullable = true)\n",
      " |-- end_time: timestamp (nullable = true)\n",
      " |-- start_station_id: integer (nullable = true)\n",
      " |-- start_station_name: string (nullable = true)\n",
      " |-- start_station_latitude: double (nullable = true)\n",
      " |-- start_station_longitude: double (nullable = true)\n",
      " |-- end_station_id: integer (nullable = true)\n",
      " |-- end_station_name: string (nullable = true)\n",
      " |-- end_station_latitude: double (nullable = true)\n",
      " |-- end_station_longitude: double (nullable = true)\n",
      " |-- bike_id: integer (nullable = true)\n",
      " |-- user_type: string (nullable = true)\n",
      " |-- member_birth_year: integer (nullable = true)\n",
      " |-- member_gender: string (nullable = true)\n",
      " |-- pyment: string (nullable = true)\n",
      " |-- distance_m: double (nullable = true)\n",
      " |-- duration_sec: long (nullable = true)\n",
      " |-- fee: double (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "917edfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "| age|        distance_m|\n",
      "+----+------------------+\n",
      "|  35| 942.3373818591812|\n",
      "|  57|3067.7986569373347|\n",
      "|null|               0.0|\n",
      "|null|1045.9655184811572|\n",
      "|  25| 635.9398610767416|\n",
      "|null|               0.0|\n",
      "|  31|               0.0|\n",
      "|null|               0.0|\n",
      "|null|               0.0|\n",
      "|null|               0.0|\n",
      "+----+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_age = df1.select(col('age'),('distance_m')).show(10)\n",
    "df_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "85440ca2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011148261513315322"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find the correlation between age and total distance\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "df1.stat.corr(\"age\",\"distance_m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3d5b9afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "| age|   avg(distance_m)|\n",
      "+----+------------------+\n",
      "|  31|1627.1747321491512|\n",
      "|  65|1550.7970469464924|\n",
      "|  53|1615.9961666112085|\n",
      "|  78| 1738.533853449056|\n",
      "|  34| 1632.586214667949|\n",
      "| 115|1258.8515568959915|\n",
      "|  81|1545.7800030706612|\n",
      "|  28|1597.8047652824787|\n",
      "|  76| 978.6525959353298|\n",
      "|  27|1614.1143983222787|\n",
      "|  26| 1268.911708273193|\n",
      "|  44| 1586.594792391467|\n",
      "| 122|1423.9429793322101|\n",
      "| 111|1891.3312419369552|\n",
      "|  47|1590.3443459610605|\n",
      "|null| 1502.649140519337|\n",
      "|  52|1680.2273796697316|\n",
      "|  40|1614.2863442246678|\n",
      "|  94|1258.9165538476107|\n",
      "|  57| 1530.291219745407|\n",
      "+----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Show the relation between the distance and the age\n",
    "df1.groupBy(\"age\").agg({\"distance_m\": \"mean\"}).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5221f6c3",
   "metadata": {},
   "source": [
    " ## 8-calculate the total cost for all customers and all subscribers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e8341",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('total_paid', \n",
    "                   round((df.distance_m/ 1000) * .35)) # assume 35 cent for every meter\n",
    "\n",
    "\n",
    "df.groupBy(\"user_type\").agg(sum('total_paid')\n",
    "                            .alias('total_paid_sum')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089e397",
   "metadata": {},
   "source": [
    " ## 9- what is the ratio of payment using cc or app wallet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9622831b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the ratio of payment using cc or app wallet\n",
    "\n",
    "df.groupBy('pyment').agg(count('*').alias('number of usage')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5466f8",
   "metadata": {},
   "source": [
    " ## 10-what is the preferred way to pay for customers and subscriber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee59e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('pyment').agg(count('*').alias('total_on_type'))\\\n",
    ".withColumn('perc', col('total_on_type') / df.count()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e6c28d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupBy('user_type', 'pyment').agg(count('*').alias('row_count')).withColumnRenamed('pyment', 'payment').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e8f6cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6125e1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea439ddb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6917306",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = r'E:\\Learning Pandas\\Data_Manupilation\\2017-fordgobike-tripdata.csv'\n",
    "\n",
    "df1 = pd.read_csv(path)\n",
    "\n",
    "df1.sample(5)\n",
    "df1.member_birth_year.dtype"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
